{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import csv, json, pickle\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# File I/O\n",
    "from pathlib import Path\n",
    "from shutil import rmtree, copyfile\n",
    "\n",
    "from subprocess import Popen\n",
    "startfile = lambda path : Popen(['xdg-open', path]) # Replacement for os.startfile() functionality, since none natively exists in Linux\n",
    "\n",
    "# Typing and class templates\n",
    "from typing import Any, Callable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Cheminformatics\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "\n",
    "# OpenForceField\n",
    "from openff.units import unit\n",
    "from openff.interchange import Interchange\n",
    "\n",
    "from openff.toolkit.topology import Topology\n",
    "from openff.toolkit.topology.molecule import FrozenMolecule, Molecule, Atom\n",
    "from openff.toolkit.utils import toolkit_registry\n",
    "from openff.toolkit.utils.toolkits import RDKitToolkitWrapper, OpenEyeToolkitWrapper, AmberToolsToolkitWrapper\n",
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "from openff.toolkit.typing.engines.smirnoff import parameters as offtk_parameters\n",
    "\n",
    "from openmm import LangevinMiddleIntegrator\n",
    "from openmm.app import Simulation, PDBReporter, StateDataReporter\n",
    "from openmm.unit import kelvin, picosecond, picoseconds, nanometer # need to do some unit conversion with both packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for loading and cataloging molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge calculation methods\n",
    "def search_mol_files(filename : str, parent_path : Path=Path.cwd()/'compatible_pdbs', extensions : tuple[str, ...]=('pdb', 'json')) -> dict[str, Path]:\n",
    "    '''Search file tree for a pdb and monomer file with matching names'''\n",
    "    mol_files = {\n",
    "        ext : path\n",
    "            for path in parent_path.glob('**/*.*')\n",
    "                for ext in extensions\n",
    "                    if path.name == f'{filename}.{ext}'\n",
    "    }\n",
    "\n",
    "    for ext in extensions:\n",
    "        if ext not in mol_files:\n",
    "            raise FileNotFoundError(f'Could not find a(n) {ext} file \\\"{filename}.{ext}\\\"')\n",
    "    else:\n",
    "        return mol_files\n",
    "\n",
    "def load_mol_and_topo(pdb_path : Path, json_path : Path, verbose : bool=False):\n",
    "    '''Load Molecule and Topology from a pdb and a monomer json file, performing residue matching on monomer units\n",
    "    Assumes that the pdb only contains has ONE simple homopolymer (will only load first molecule if multiple are present'''\n",
    "    off_topology, _, error = Topology.from_pdb_and_monomer_info(str(pdb_path), json_path, strict=True, verbose=verbose)\n",
    "    mol = next(off_topology.molecules) # get the first molecule (assumed to be the polymer of interest)\n",
    "\n",
    "    return mol, off_topology\n",
    "\n",
    "def poll_and_count_molecules(pdb_folder : Path, outname : str=None, save_fmt : str='json') -> dict[str, int]:\n",
    "    '''Takes a path to a folder containing multiple .pdb files and produces\n",
    "    a csv listing all found molecules and how many atoms each contains'''\n",
    "    mol_sizes = {}\n",
    "    mol_names = {path.stem for path in pdb_folder.iterdir()}\n",
    "    for name in mol_names:\n",
    "        try:\n",
    "            mol_files = search_mol_files(name)\n",
    "            mol, topology = load_mol_and_topo(mol_files['pdb'], mol_files['json'])  # will raise exception if files for molecule are not found\n",
    "            mol_sizes[name] = len(mol.atoms)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    if outname is not None: # also write to file if a name for the output is specified\n",
    "        outpath = pdb_folder/f'{outname}.{save_fmt}'\n",
    "        outpath.touch()\n",
    "\n",
    "        with outpath.open('w') as mol_file:\n",
    "            if save_fmt == 'csv':\n",
    "                writer = csv.writer(mol_file, delimiter=',')\n",
    "                writer.writerow(['Molecule Name', '# Atoms']) # add columns headers\n",
    "                for mol_name, mol_size in mol_sizes.items():\n",
    "                    writer.writerow([mol_name, mol_size])\n",
    "\n",
    "            elif save_fmt == 'json':\n",
    "                json.dump(mol_sizes, mol_file, indent=4)\n",
    "            else:\n",
    "                raise NotImplementedError(f'No save method for .{save_fmt} output supported')\n",
    "\n",
    "    return mol_sizes\n",
    "\n",
    "def sort_dict_by_values(targ_dict : dict, reverse : bool=False) -> dict[Any, Any]:\n",
    "    '''Sort a dictionary according to the values of each key'''\n",
    "    return { # sort dict in ascending order by size\n",
    "        key : targ_dict[key]\n",
    "            for key in sorted(targ_dict, key=lambda k : targ_dict[k], reverse=reverse)\n",
    "    }\n",
    "\n",
    "def catalog_molecules(pdb_folder : Path, monomer_folder : Path, save_fmt : str=None, outpath : Path=None) -> Optional[dict[str, int]]:\n",
    "    '''Takes paths to folders containing pdbs and corresponding monomer jsons files (assumes jsons will have same file name)\n",
    "    Will catalog names and molecules sizes of each molecule which has compatible version of both files types present\n",
    "    Can return output as dict or save to file (specified by \"saev_fmt\" kwarg)'''\n",
    "    mol_sizes = {}\n",
    "\n",
    "    pdb_dir = Path('compatible_pdbs/simple_polymers')\n",
    "    mono_dir = Path('compatible_pdbs/simple_polymers')\n",
    "\n",
    "    for path in pdb_folder.iterdir():\n",
    "        name = path.stem\n",
    "        mono_path = mono_dir/f'{path.stem}.json'\n",
    "\n",
    "        if (path.suffix == '.pdb') and mono_path.exists(): # if the current file is a pdb with a matching-named monomer json\n",
    "            mol = Molecule(str(path)) # OpenFF doesn't like PosixPaths for some reason\n",
    "            mol_sizes[name] = len(mol.atoms)\n",
    "    mol_sizes = sort_dict_by_values(mol_sizes) # sort in ascending order by molecule size\n",
    "\n",
    "    # Saving logic begins\n",
    "    if save_fmt is None:\n",
    "        return mol_sizes # return None if saving to file\n",
    "\n",
    "    if outpath is None: # TOSELF: important that this is only checked AFTER establishing the format is specified\n",
    "        raise ValueError(f'No output path specified for saving to .{save_fmt}')\n",
    "\n",
    "    if save_fmt == 'csv':\n",
    "        with outpath.open('w') as mol_file:\n",
    "            writer = csv.writer(mol_file, delimiter=',')\n",
    "            writer.writerow(['Molecule Name', '# Atoms']) # add columns headers\n",
    "            for mol_name, mol_size in mol_sizes.items():\n",
    "                writer.writerow([mol_name, mol_size])                \n",
    "    elif save_fmt == 'json':\n",
    "        with outpath.open('w') as mol_file:\n",
    "            json.dump(mol_sizes, mol_file, indent=4)\n",
    "    else:\n",
    "        raise NotImplementedError(f'No save method for .{save_fmt} output supported')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_molecule_charges(mol : Molecule, toolkit_method : str='openeye', partial_charge_method : str='am1bcc') -> Molecule:\n",
    "    '''Takes a Molecule object and computes partial charges with AM1BCC using toolkit method of choice. Returns charged molecule'''\n",
    "    toolkits = {\n",
    "        'rdkit' : RDKitToolkitWrapper,\n",
    "        'openeye' : OpenEyeToolkitWrapper,\n",
    "        'ambertools' : AmberToolsToolkitWrapper\n",
    "    }\n",
    "\n",
    "    mol.assign_partial_charges( # finally, assign partial charges using those 10 conformers generated \n",
    "        partial_charge_method=partial_charge_method, \n",
    "        toolkit_registry=toolkits.get(toolkit_method)()\n",
    "    )\n",
    "    charged_mol = mol # rename for clarity\n",
    "    # get some conformers to run elf10 charge method. By default, `mol.assign_partial_charges`\n",
    "    # uses 500 conformers, but we can generate and use 10 here for demonstration\n",
    "    # charged_mol.generate_conformers(\n",
    "    #     n_conformers=10,\n",
    "    #     rms_cutoff=0.25 * unit.angstrom,\n",
    "    #     make_carboxylic_acids_cis=True,\n",
    "    #     toolkit_registry=RDKitToolkitWrapper()\n",
    "    # ) # very slow for large polymers! \n",
    "\n",
    "    print(f'final molecular charges: {charged_mol.partial_charges}')\n",
    "    # note: the charged_mol has metadata about which monomers were assigned where as a result of the chemicaly info assignment.\n",
    "    # This can be a way to break up the molecule into repeating sections to partition the library charges \n",
    "    for atom in charged_mol.atoms:\n",
    "        assert(atom.metadata['already_matched'] == True)\n",
    "        # print(atom.metadata['residue_name'])\n",
    "    \n",
    "    return charged_mol # code for exact how thely above function works can be found in openff/toolkit/utils/openeye_wrapper.py under the assign_partial_charges()\n",
    "\n",
    "# charge averaging methods\n",
    "ChargeMap = dict[int, float] # makes typehinting clearer\n",
    "\n",
    "class ChargeDistributionStrategy(ABC):\n",
    "    '''Interface for defining how excess charge should be distributed within averaged residues\n",
    "    to ensure an overall net 0 charge for each monomer fragment'''\n",
    "    @abstractmethod\n",
    "    def determine_distribution(self, net_charge : float, base_charges : ChargeMap, struct : nx.Graph) -> ChargeMap:\n",
    "        pass\n",
    "\n",
    "class UniformDistributionStrategy(ChargeDistributionStrategy):\n",
    "    '''Simplest possible strategy, distribute any excess charge evenly among all molecules in residue\n",
    "    Each charge effectively becomes an average of averages when viewed in the context of the whole polymer'''\n",
    "    def determine_distribution(self, net_charge : float, base_charges: ChargeMap, struct: nx.Graph) -> ChargeMap:\n",
    "        charge_offset = net_charge / len(base_charges) # net charge divided evenly amongst atoms (average of averages, effectively)\n",
    "        return {sub_id : charge_offset for sub_id in base_charges}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Accumulator:\n",
    "    '''Compact container for accumulating averages'''\n",
    "    sum : float = 0.0\n",
    "    count : int = 0\n",
    "\n",
    "    @property\n",
    "    def average(self) -> float:\n",
    "        return self.sum / self.count\n",
    "\n",
    "@dataclass\n",
    "class ChargedResidue:\n",
    "    '''Dataclass for more conveniently storing averaged charges for a residue group'''\n",
    "    charges : ChargeMap\n",
    "    residue_name : str\n",
    "    SMARTS : str\n",
    "    mol_fragment : Chem.rdchem.Mol\n",
    "\n",
    "    CDS : ChargeDistributionStrategy = field(default_factory=UniformDistributionStrategy) # set default strategy here\n",
    "\n",
    "    def distrib_mono_charges(self) -> None:\n",
    "        '''Distribute any excess charge amongst residue to ensure neutral, integral net charge'''\n",
    "        net_charge = sum(chg for chg in self.charges.values())\n",
    "        distrib = self.CDS.determine_distribution(net_charge, base_charges=self.charges, struct=self.mol_fragment)\n",
    "        for sub_id, charge in self.charges.items():\n",
    "            self.charges[sub_id] = charge - distrib[sub_id] # subtract respective charge offsets from each atom's partial charge\n",
    "\n",
    "\n",
    "def find_repr_residues(cmol : Molecule) -> dict[str, int]:\n",
    "    '''Determine names and smallest residue numbers of all unique residues in charged molecule\n",
    "    Used as representatives for generating labelled SMARTS strings '''\n",
    "    rep_res_nums = defaultdict(set) # numbers of representative groups for each unique residue, used to build SMARTS strings\n",
    "    for atom in cmol.atoms: \n",
    "        rep_res_nums[atom.metadata['residue_name']].add(atom.metadata['residue_number']) # collect unique residue numbers\n",
    "\n",
    "    for res_name, ids in rep_res_nums.items():\n",
    "        rep_res_nums[res_name] = min(ids) # choose group with smallest id of each residue to denote representative group\n",
    "\n",
    "    return rep_res_nums\n",
    "\n",
    "def get_averaged_charges_orig(cmol : Molecule, monomer_data : dict[str, dict], distrib_mono_charges : bool=False) -> list[ChargedResidue]:\n",
    "    '''Takes a charged molecule and a dict of monomer structure data and averages charges for each repeating residue. \n",
    "    Returns a list of ChargedResidue objects each of which holds:\n",
    "        - A dict of the averaged charges by atom \n",
    "        - The name of the residue associated with the charges\n",
    "        - A SMARTS string of the residue's structure'''\n",
    "    rdmol = cmol.to_rdkit() # create rdkit representation of Molecule to allow for SMARTS generation\n",
    "    rep_res_nums = find_repr_residues(cmol) # determine ids of representatives of each unique residue\n",
    "\n",
    "    atom_ids_for_SMARTS = defaultdict(list)\n",
    "    res_charge_accums   = defaultdict(lambda : defaultdict(Accumulator))\n",
    "    for atom in cmol.atoms: # accumulate counts and charge values across matching substructures\n",
    "        res_name, res_num     = atom.metadata['residue_name']   , atom.metadata['residue_number']\n",
    "        substruct_id, atom_id = atom.metadata['substructure_id'], atom.metadata['pdb_atom_id']\n",
    "\n",
    "        if res_num == rep_res_nums[res_name]: # if atom is member of representative group for any residue...\n",
    "            atom_ids_for_SMARTS[res_name].append(atom_id)             # ...collect pdb id...\n",
    "            rdmol.GetAtomWithIdx(atom_id).SetAtomMapNum(substruct_id) # ...and set atom number for labelling in SMARTS string\n",
    "\n",
    "        curr_accum = res_charge_accums[res_name][substruct_id] # accumulate charge info for averaging\n",
    "        curr_accum.sum += atom.partial_charge.magnitude # eschew units (easier to handle, added back when writing to XML)\n",
    "        curr_accum.count += 1\n",
    "\n",
    "    avg_charges_by_residue = []\n",
    "    for res_name, charge_map in res_charge_accums.items():\n",
    "        # SMARTS = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=atom_ids_for_SMARTS[res_name]) # determine SMARTS for the current residue's representative group\n",
    "        SMARTS = monomer_data['monomers'][res_name] # extract SMARTS string from monomer data\n",
    "        charge_map = {substruct_id : accum.average for substruct_id, accum in charge_map.items()} \n",
    "\n",
    "        if distrib_mono_charges: # distribute any excess average charge among monomer atoms to ensure no net charge per monomer\n",
    "            chg_offset = sum(avg for avg in charge_map.values()) / len(charge_map)\n",
    "            charge_map = {sub_id : avg - chg_offset for sub_id, avg in charge_map.items()}\n",
    "        \n",
    "        avg_charges_by_residue.append(ChargedResidue(charges=charge_map, residue_name=res_name, SMARTS=SMARTS))\n",
    "\n",
    "    return avg_charges_by_residue\n",
    "\n",
    "def get_averaged_charges(cmol : Molecule, monomer_data : dict[str, dict], distrib_mono_charges : bool=True) -> list[ChargedResidue]:\n",
    "    '''Takes a charged molecule and a dict of monomer SMIRKS strings and averages charges for each repeating residue. \n",
    "    Returns a list of ChargedResidue objects, each of which holds:\n",
    "        - A dict of the averaged charges by atom \n",
    "        - The name of the residue associated with the charges\n",
    "        - A SMARTS string of the residue's structure\n",
    "        - An nx.Graph representing the structure of the residue'''\n",
    "    # rdmol = cmol.to_rdkit() # create rdkit representation of Molecule to allow for SMARTS generation\n",
    "    mol_graph = cmol.to_networkx()\n",
    "    rep_res_nums = find_repr_residues(cmol) # determine ids of representatives of each unique residue\n",
    "\n",
    "    atom_id_mapping   = defaultdict(lambda : defaultdict(int))\n",
    "    res_charge_accums = defaultdict(lambda : defaultdict(Accumulator))\n",
    "    for atom in cmol.atoms: # accumulate counts and charge values across matching substructures\n",
    "        res_name, res_num     = atom.metadata['residue_name'   ], atom.metadata['residue_number']\n",
    "        substruct_id, atom_id = atom.metadata['substructure_id'], atom.metadata['pdb_atom_id'   ]\n",
    "\n",
    "        if res_num == rep_res_nums[res_name]: # if atom is member of representative group for any residue...\n",
    "            # rdmol.GetAtomWithIdx(atom_id).SetAtomMapNum(atom_id)  # ...and set atom number for labelling in SMARTS string\n",
    "            atom_id_mapping[res_name][atom_id] = (substruct_id, atom.symbol) # ...collect pdb id...\n",
    "\n",
    "        curr_accum = res_charge_accums[res_name][substruct_id] # accumulate charge info for averaging\n",
    "        curr_accum.sum += atom.partial_charge.magnitude # eschew units (easier to handle, added back when writing to XML)\n",
    "        curr_accum.count += 1\n",
    "\n",
    "    avg_charges_by_residue = []\n",
    "    for res_name, charge_map in res_charge_accums.items():\n",
    "        # rdSMARTS = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=atom_id_mapping[res_name].keys()) # determine SMARTS for the current residue's representative group\n",
    "        # mol_frag = rdmolfiles.MolFromSmarts(rdSMARTS) # create fragment from rdkit SMARTS to avoid wild atoms (using rdkit over nx.subgraph for more detailed atomwise info)\n",
    "        \n",
    "        SMARTS = monomer_data['monomers'][res_name] # extract SMARTS string from monomer data\n",
    "        charge_map = {substruct_id + 1: accum.average for substruct_id, accum in charge_map.items()} \n",
    "        atom_id_map = atom_id_mapping[res_name]\n",
    "\n",
    "        mol_frag = mol_graph.subgraph(atom_id_map.keys()) # isolate subgraph of residue to obtain connectivity info for charge redistribution\n",
    "        for atom_id, (substruct_id, symbol) in atom_id_map.items(): # assign additional useful info not present by default in graph\n",
    "            mol_frag.nodes[atom_id]['substruct_id'] = substruct_id\n",
    "            mol_frag.nodes[atom_id]['symbol'] = symbol\n",
    "\n",
    "        chgd_res = ChargedResidue(\n",
    "            charges=charge_map,\n",
    "            residue_name=res_name,\n",
    "            SMARTS=SMARTS,\n",
    "            mol_fragment=mol_frag\n",
    "        )\n",
    "        if distrib_mono_charges: # only distribute charges if explicitly called for (enabled by default)\n",
    "            chgd_res.distrib_mono_charges()\n",
    "        avg_charges_by_residue.append(chgd_res)\n",
    "\n",
    "    return avg_charges_by_residue, atom_id_mapping\n",
    "\n",
    "def write_new_library_charges(avgs : list[ChargedResidue], offxml_src : Path, output_path : Path) -> tuple[ForceField, list[offtk_parameters.LibraryChargeHandler]]:\n",
    "    '''Takes dict of residue-averaged charges to generate and append library charges to an .offxml file of choice, creating a new xml with the specified filename'''\n",
    "    assert(output_path.suffix == '.offxml') # ensure output path is pointing to correct file type\n",
    "    forcefield = ForceField(offxml_src)     # simpler to add library charges through forcefield API than to directly write to xml\n",
    "    lc_handler = forcefield[\"LibraryCharges\"]\n",
    "\n",
    "    lib_chgs = [] #  all library charges generated from the averaged charges for each residue\n",
    "    for averaged_res in avgs:\n",
    "        lc_entry = { # stringify charges into form usable for library charges\n",
    "            f'charge{cid}' : f'{charge} * elementary_charge' # +1 accounts for 1-index to 0-index when going from smirks atom ids to substructure ids\n",
    "                for cid, charge in averaged_res.charges.items()\n",
    "        } \n",
    "\n",
    "        lc_entry['smirks'] = averaged_res.SMARTS # add SMIRKS string to library charge entry to allow for correct labelling\n",
    "        lc_params = offtk_parameters.LibraryChargeHandler.LibraryChargeType(allow_cosmetic_attributes=True, **lc_entry) # must enable cosmetic params for general kwarg passing\n",
    "        \n",
    "        lc_handler.add_parameter(parameter=lc_params)\n",
    "        lib_chgs.append(lc_params)  # record library charges for reference\n",
    "    forcefield.to_file(output_path) # write modified library charges to new xml (avoid overwrites in case of mistakes)\n",
    "    \n",
    "    return forcefield, lib_chgs\n",
    "\n",
    "# OpenMM simulation methods\n",
    "def create_sim_from_interchange(interchange : Interchange) -> Simulation:\n",
    "    '''Sets up a Simulation object using topology and force field data as specified by an Interchange object\n",
    "    Converts topologies and positions to OpenMM format from OpenFF formats (can support GROMACS format too in future)'''\n",
    "    openmm_sys = interchange.to_openmm(combine_nonbonded_forces=True) \n",
    "    openmm_top = interchange.topology.to_openmm()\n",
    "    openmm_pos = interchange.positions.m_as(unit.nanometer) * nanometer\n",
    "    integrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.0005*picoseconds)\n",
    "\n",
    "    print(openmm_sys.getDefaultPeriodicBoxVectors())\n",
    "\n",
    "    simulation = Simulation(openmm_top, openmm_sys, integrator)\n",
    "    simulation.context.setPositions(openmm_pos)\n",
    "\n",
    "    return simulation\n",
    "\n",
    "def run_simulation(simulation : Simulation, output_folder : Path, output_name : str='md_sim', num_steps=1000, record_freq=10) -> None:\n",
    "    '''Takes a Simulation object, performs energy minimization, and runs simulation for specified number of time steps\n",
    "    Recording PBD frames and numerical data to file at the specified frequency'''\n",
    "    folder_name = str(output_folder) # for some reason OpenMM simulations don;t like Path objects (only take strings)\n",
    "\n",
    "    # for saving pdb frames and reporting state/energy data\n",
    "    pdb_rep = PDBReporter(f'{folder_name}/{output_name}_frames.pdb', record_freq)  # save frames at the specified interval\n",
    "    state_rep = StateDataReporter(f'{folder_name}/{output_name}_data.csv', record_freq, step=True, potentialEnergy=True, temperature=True)\n",
    "    reporters = (pdb_rep, state_rep)\n",
    "\n",
    "    # minimize and run simulation\n",
    "    simulation.minimizeEnergy()\n",
    "    simulation.saveCheckpoint(f'{folder_name}/{output_name}_checkpoint.chk') # save initial minimal state to simplify reloading process\n",
    "    for rep in reporters:\n",
    "        simulation.reporters.append(rep) # add any desired reporters to simulaiton for tracking\n",
    "    simulation.step(num_steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and comparing loading of PDBs generated through different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_name = 'naturalrubber'\n",
    "\n",
    "pdb_folder = Path(f'mbuild_polymers/PDB save test/{mol_name}')\n",
    "fmts = ['orig', 'mdtraj', 'mbuild', 'mda']\n",
    "\n",
    "pdb_paths = {}\n",
    "for path in pdb_folder.iterdir():\n",
    "    for fmt in fmts:    \n",
    "        if fmt in path.stem:\n",
    "            fmts.pop(fmts.index(fmt))\n",
    "            pdb_paths[fmt] = path\n",
    "print(pdb_paths)\n",
    "\n",
    "mono_path = Path(f'compatible_pdbs/simple_polymers/{mol_name}.json')\n",
    "pdb_folder = Path('mbuild_polymers/PDB save test/polyethylmethacrylate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_path = pdb_paths['orig']\n",
    "top, substruct, err = Topology.from_pdb_and_monomer_info(str(pdb_path), mono_path, strict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success, fail, errors = [], [], []\n",
    "for fmt, path in pdb_paths.items():\n",
    "    if fmt != 'mda':\n",
    "        try:\n",
    "            # mol = Topology.from_pdb_and_monomer_info(str(), toolkit_registry=tk_reg)\n",
    "            mol, topo = load_mol_and_topo(str(path), mono_path, verbose=True)\n",
    "            # cmol = generate_molecule_charges(mol)\n",
    "            success.append(fmt)\n",
    "        except Exception as e:\n",
    "            print(f'{fmt} failed')\n",
    "            fail.append(fmt)\n",
    "            errors.append(e)\n",
    "\n",
    "success, fail, errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug to determine which SMIRKs the openff unit parser doesn't like and why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, xml\n",
    "import xml.etree.ElementTree as ET\n",
    "from pint.errors import DefinitionSyntaxError\n",
    "\n",
    "# define paths here\n",
    "xml_dir = Path('xml_examples')\n",
    "offxml_paths = [path for path in xml_dir.iterdir() if path.suffix in ('.xml', '.offxml')]\n",
    "# print(offxml_paths)\n",
    "\n",
    "# xml parsing code begins\n",
    "for xml_path in offxml_paths:\n",
    "    # xml_path = Path('xml_examples/base_library_charges.offxml')\n",
    "    # xml_path = Path('xml_examples/openff_unconstrained-2.0.0.offxml')\n",
    "    print('\\n', xml_path.stem)\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    error_types = defaultdict(list)\n",
    "    all_smirks = {\n",
    "        'Problem' : defaultdict(list),\n",
    "        'Working' : defaultdict(list),\n",
    "    }\n",
    "\n",
    "    # sort entries based on which type of error they raise\n",
    "    for entry_type in ('Angle', 'Proper'):\n",
    "        for entry in root.iter(entry_type):\n",
    "            try:\n",
    "                u = unit.Quantity(entry.get('smirks')) \n",
    "            except Exception as e:\n",
    "                error_types[type(e)].append(entry.get('id')) \n",
    "                err_label = 'Problem' if type(e) == DefinitionSyntaxError else 'Working'\n",
    "                all_smirks[err_label][entry_type].append(entry.get('smirks'))\n",
    "    error_counts = {err : len(instances) for err, instances in error_types.items()}\n",
    "\n",
    "    print(error_counts)\n",
    "    # print(all_smirks)\n",
    "\n",
    "    # check if all atoms in smirks are of wild type\n",
    "    ATOM_TYPE = re.compile('\\[(.*?)[:|;]')\n",
    "    for working_status, smirks_subset in all_smirks.items():\n",
    "        print('\\t', working_status)\n",
    "        atom_types = []\n",
    "        for entry_type, coll in smirks_subset.items():\n",
    "            # print('\\t', entry_type)\n",
    "            for entry in coll:\n",
    "                atom_types.append( set(re.findall(ATOM_TYPE, entry)) )\n",
    "                # print('\\t\\t', set(re.findall(ATOM_TYPE, entry)) )#, entry )\n",
    "\n",
    "        print('\\t\\tAll atoms wild type:' , all(typeset == {'*'} for typeset in atom_types) and atom_types != [] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = ForceField(str(xml_dir/'minimal xml.offxml'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate copy of PDBs folder sorted by molecule, along with respective packmol .inp files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_solv_inp_from_template(outname : str, outdir : Path, polymer_pdb : Path,\n",
    "         N : int=200,\n",
    "         dim : float=40.0,\n",
    "         solvent_pdb : Path=Path('packmol_solva/water/water.pdb'),\n",
    "         template_src : Path=Path('packmol_solva/inp_templates/solv_polymer_template.inp')\n",
    "    ) -> None:\n",
    "    '''\n",
    "    Function for programmatically generating packmol .inp files for solvating arbitrary polymer in a cube of water\n",
    "\n",
    "    Args:\n",
    "    outname : str       = name for the resulting .inp file\n",
    "    outdir : Path       = the target directory to save the resulting .inp file into\n",
    "    polymer_pdb : path  = path to the desired polymer .pdb file\n",
    "    \n",
    "    solvent_pdb : path  = path to the desired solvent .pdb file\n",
    "    N : int             = number of solvent molecule to populate into box \n",
    "    dim : float         = edge length of solvent cube (in angstroms) - polymer will be placed at center (all coords N/2)\n",
    "    template_src : Path = the base template file to populate values into\n",
    "    '''\n",
    "    repl_dict = {\n",
    "        '$POLYMER_FILE' : polymer_pdb.name,\n",
    "        '$SOLVENT_FILE' : solvent_pdb.name,\n",
    "        '$N' : N,\n",
    "        '$R' : dim / 2.0,\n",
    "        '$D' : dim,\n",
    "        '$OUTNAME' : outname\n",
    "    }\n",
    "\n",
    "    with template_src.open('r') as src_file:\n",
    "        code = src_file.read()\n",
    "\n",
    "    for token, value in repl_dict.items():\n",
    "        code = code.replace(token, str(value))\n",
    "\n",
    "    outpath = outdir/f'{outname}.inp'\n",
    "    outpath.touch()\n",
    "    with outpath.open('w') as packmol_file:\n",
    "        packmol_file.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "water_pdb = Path('compatible_pdbs/solvents/water.pdb')\n",
    "pm_script = Path('packmol_solva/protein_example/solvprotein.inp')\n",
    "\n",
    "input = Path('compatible_pdbs/simple_polymers')\n",
    "output = Path('packmol_solva/simple_polymers_sorted')\n",
    "output.mkdir(exist_ok=True)\n",
    "\n",
    "fmts = ('.json', '.pdb')\n",
    "blacklist = ('Available Polymers.json', 'New Linear Polymers.json')\n",
    "\n",
    "for file in input.iterdir():\n",
    "    if file.suffix in fmts and file.name not in blacklist:\n",
    "        mol_name = file.stem\n",
    "        save_dir = output/mol_name\n",
    "        save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        new_pdb_path = save_dir/file.name\n",
    "        copyfile(file, new_pdb_path)\n",
    "        copyfile(water_pdb, save_dir/'water.pdb')\n",
    "        poly_solv_inp_from_template(f'solv_{mol_name}', save_dir, new_pdb_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate \"watery\" versions of all available jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = ('Available Polymers.json', 'New Linear Polymers.json')\n",
    "output = Path('watery_jsons')\n",
    "output.mkdir(exist_ok=True)\n",
    "\n",
    "polymer_folder = Path('compatible_pdbs/simple_polymers')\n",
    "for path in polymer_folder.iterdir():\n",
    "    if path.suffix == '.json' and path.name not in blacklist:\n",
    "        with path.open('r') as mono_json:\n",
    "            monomer_data = json.load(mono_json)\n",
    "            monomer_data['monomers']['water'] = \"[#1:1]-[#8:3]-[#1:2]\"\n",
    "            monomer_data['caps']['water'] = []\n",
    "\n",
    "        outpath = output/path.name\n",
    "        outpath.touch()\n",
    "\n",
    "        with outpath.open('w') as new_mono_json:\n",
    "            json.dump(monomer_data, new_mono_json, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running averaging code for test molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all molecules which will be charge averaged and simulated\n",
    "pdb_folder = Path.cwd()/'compatible_pdbs'/'simple_polymers'\n",
    "counts_path = pdb_folder/'Available Polymers.json'\n",
    "\n",
    "if counts_path.exists(): # if molecules have already been polled, load names/sizes from file...\n",
    "    with counts_path.open('r') as counts_file:\n",
    "        mol_sizes = json.load(counts_file)\n",
    "else:\n",
    "    mol_sizes = poll_and_count_molecules(pdb_folder=pdb_folder, outname=counts_path.stem, save_fmt='json') # otherwise, repoll and save to file\n",
    "\n",
    "hard_polymers = ['vulcanizedrubber', 'polyphenylenesulfone'] # pathological or otherwise difficult-to-run polymers that I've encountered\n",
    "mols_to_use = [mol_name\n",
    "    for mol_name, mol_size in mol_sizes.items()\n",
    "        if mol_size < 150 # only keep polymers which are small enough for AM1BCC...\n",
    "            and mol_name not in hard_polymers # ... and not manually excluded\n",
    "]\n",
    "\n",
    "print(mols_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform charge averaging on all target molecules which don't already have averaged LCs; \n",
    "# Load forcefield for those which already do \n",
    "sample_mols = ['naturalrubber']\n",
    "run_sims = True\n",
    "prevent_overwrites = False\n",
    "distrib_mono_charges = True\n",
    "\n",
    "offxml_src = Path('xml_examples/base_library_charges.offxml')\n",
    "polymer_folder = Path('compatible_pdbs/simple_polymers')\n",
    "pickle_folder = Path('pickled_molecules/for openff-units 0.2.0')\n",
    "\n",
    "def get_cmol(mol : Molecule, pickle_path : Path) -> Molecule:\n",
    "    '''More efficient method for repeatedly obtaining a charged Molecule\n",
    "    If no molecule file is found, perform AM1BCC and save to file, otherwise load from file'''\n",
    "    if not pickle_path.exists():\n",
    "        logging.info('No extant pickled charged Molecule found, performing charging...')\n",
    "        cmol = generate_molecule_charges(mol, toolkit_method='openeye', partial_charge_method='am1bcc') # perform AM1BCC\n",
    "        with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "            pickle.dump(cmol, pickle_file)\n",
    "    else:\n",
    "        logging.info('Unpickling charged Molecule...')\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "    return cmol\n",
    "\n",
    "for mol_name in sample_mols: #mols_to_use: #\n",
    "    # DEFINING PATHS, CREATING FOLDERS, AND FETCHING FILES\n",
    "    logging.info(f'Current molecule: {mol_name}')\n",
    "    # pdb_path = Path(f'compatible_pdbs/simple_polymers/{mol_name}.pdb')\n",
    "    # pdb_path = Path(f'mbuild_polymers/10-monomer chains/{mol_name}-N=10.pdb')\n",
    "    pdb_path = Path(f'packmol_solva/simple_polymers_sorted/naturalrubber/solv{mol_name}.pdb')\n",
    "\n",
    "    charged_json = Path(f'charged_jsons/{mol_name}_with_charges.json')\n",
    "    default_json = polymer_folder/f'{mol_name}.json'\n",
    "    # if charged_json.exists():\n",
    "    #     logging.info('Found monomer JSON with precalculated charge data, using...')\n",
    "    #     json_path = charged_json\n",
    "    # else:\n",
    "    #     logging.info('Using default monomer JSON...')\n",
    "    #     json_path = default_json\n",
    "    json_path = Path(f'watery_jsons/{mol_name}.json')# default_json\n",
    "    # json_path =  default_json\n",
    "\n",
    "    with json_path.open('r') as json_file:\n",
    "        mono_data = json.load(json_file)\n",
    "    \n",
    "    output_folder = Path(f'averaged_polymers/{mol_name}')\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "    lc_path = output_folder/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "    pickle_path = pickle_folder/f'{mol_name}.pkl'\n",
    "\n",
    "    # LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "    logging.info(f'Loading and matching molecule \"{mol_name}\"...')\n",
    "    mol, topology = load_mol_and_topo(pdb_path, json_path)  # will raise exception if files for molecule are not found\n",
    "    \n",
    "    if prevent_overwrites and lc_path.exists(): # check if library charges have already been generated for this molecule\n",
    "        logging.info('Obtaining partial charges from Library Charge xml...')\n",
    "        forcefield = ForceField(lc_path, allow_cosmetic_attributes=True)\n",
    "    else:\n",
    "        cmol = get_cmol(mol, pickle_path=pickle_path)\n",
    "        #clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "        logging.info(f'Averaging charges over {mol_name} residues...')\n",
    "        avgs, atom_id_mapping = get_averaged_charges(cmol, monomer_data=mono_data, distrib_mono_charges=distrib_mono_charges) # average charges over unique residues - placed after clear so we can see what averages are computed\n",
    "        for averaged_res in avgs:\n",
    "            print(averaged_res, '\\n')\n",
    "\n",
    "        logging.warning('Library Charge file not found OR overwrite allowed, writing new Library Charge xml...')\n",
    "        forcefield, lib_chgs = write_new_library_charges(avgs, offxml_src, output_path=lc_path)\n",
    "        \n",
    "        # CREATE JSON WITH AVERAGED CHARGES IF ONE DOES NOT ALREADY EXIST\n",
    "        if not charged_json.exists():\n",
    "            logging.info('Writing new monomer JSON with charge data...')\n",
    "            with default_json.open('r') as old_json:\n",
    "                json_dat = json.load(old_json)\n",
    "\n",
    "            charge_entry = {avgd_res.residue_name : avgd_res.charges for avgd_res in avgs}\n",
    "            json_dat['charges'] = charge_entry\n",
    "\n",
    "            charged_json.touch()\n",
    "            with charged_json.open('w') as new_json:\n",
    "                json.dump(json_dat, new_json, indent=4)\n",
    "\n",
    "    # RUN OpenMM SIMULATION FOR TARGET MOLECULE\n",
    "    if run_sims:\n",
    "        logging.info('Running OpenMM sim...')\n",
    "        forcefield = ForceField(lc_path, allow_cosmetic_attributes=True)\n",
    "        interchange = Interchange.from_smirnoff(force_field=forcefield, topology=topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "        sim = create_sim_from_interchange(interchange)\n",
    "        run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=10000, record_freq=10)\n",
    "    logging.info(f'Successfully completed actions on {mol_name}\\n')\n",
    "    startfile(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.system.usesPeriodicBoundaryConditions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('compatible_pdbs/solvents/water.pdb')\n",
    "q = Path('compatible_pdbs/solvents/water.json')\n",
    "\n",
    "mol, topo = load_mol_and_topo(p, q)\n",
    "cmol = generate_molecule_charges(mol)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing TIP3P water solvation with OpenMM tools (Modeller.addSolvent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openmm import Vec3\n",
    "from openmm.app import Modeller\n",
    "from openmm.app import ForceField as ForceField2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_path = Path('xml_examples/tip3p.offxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Running OpenMM sim...')\n",
    "forcefield = ForceField(lc_path, water_path, allow_cosmetic_attributes=True)\n",
    "interchange = Interchange.from_smirnoff(force_field=forcefield, topology=topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "sim = create_sim_from_interchange(interchange)\n",
    "run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=10000, record_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openmm_top = interchange.topology.to_openmm()\n",
    "openmm_pos = interchange.positions.m_as(unit.nanometer) * nanometer\n",
    "openmm_sys = interchange.to_openmm(combine_nonbonded_forces=True) \n",
    "\n",
    "forcefield = ForceField2(lc_path, water_path)\n",
    "\n",
    "modeller = Modeller(openmm_top, openmm_pos)\n",
    "# modeller.addSolvent(ff, model='tip3p')\n",
    "modeller.addSolvent(forcefield, boxSize=Vec3(5.0, 3.5, 3.5) * nanometer, model='tip3p')\n",
    "\n",
    "integrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.0005*picoseconds)\n",
    "\n",
    "# simulation = Simulation(modeller.topology, openmm_sys, integrator)\n",
    "# simulation.context.setPositions(modeller.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(openmm_top.addResidue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residues = [i for i in openmm_top.residues()]\n",
    "residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interchange.to_openmm()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Code for fragment assignment and charge distribution strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_name = 'PEO_PLGA'#'polyethylmethacrylate'\n",
    "\n",
    "pdb_path = Path(f'compatible_pdbs/simple_polymers/{mol_name}.pdb')\n",
    "charged_json = Path(f'charged_jsons/{mol_name}_with_charges.json')\n",
    "default_json = polymer_folder/f'{mol_name}.json'\n",
    "if charged_json.exists():\n",
    "    json_path = charged_json\n",
    "else:\n",
    "    json_path = default_json\n",
    "\n",
    "with json_path.open('r') as json_file:\n",
    "    mono_data = json.load(json_file)\n",
    "\n",
    "pickle_path = pickle_folder/f'{mol_name}.pkl'\n",
    "mol, topology = load_mol_and_topo(pdb_path, json_path)  # will raise exception if files for molecule are not found\n",
    "cmol = get_cmol(mol, pickle_path=pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs, atom_id_mapping = get_averaged_charges(cmol, mono_data, distrib_mono_charges=False)\n",
    "\n",
    "print(avgs[0].charges) # show charged before and after distribution\n",
    "avgs[0].distrib_mono_charges()\n",
    "print(avgs[0].charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in avgs[0].mol_fragment.nodes:\n",
    "    print(i, avgs[0].mol_fragment.nodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(avgs[0].mol_fragment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing pickling of molecules to avoid constantly rerunning AM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_name = 'naturalrubber'\n",
    "\n",
    "polymer_folder = Path('compatible_pdbs/simple_polymers')\n",
    "pickle_folder = Path('pickled_molecules')\n",
    "\n",
    "pdb_path = Path(f'compatible_pdbs/simple_polymers/{mol_name}.pdb')\n",
    "charged_json = Path(f'charged_jsons/{mol_name}_with_charges.json')\n",
    "default_json = polymer_folder/f'{mol_name}.json'\n",
    "json_path = charged_json if charged_json.exists() else default_json\n",
    "\n",
    "def get_cmol(mol : Molecule, pickle_path : Path):\n",
    "    '''More efficient method for repeatedly obtaining a charged Molecule\n",
    "    If no molecule file is found, perform AM1BCC and save to file, otherwise load from file'''\n",
    "    if not pickle_path.exists():\n",
    "        cmol = generate_molecule_charges(mol, toolkit_method='openeye', partial_charge_method='am1bcc') # perform AM1BCC\n",
    "        with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "            pickle.dump(cmol, pickle_file)\n",
    "    else:\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "    return cmol\n",
    "\n",
    "cmol = get_cmol(mol, pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing to determine if correct substructure ids are being applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmol = cmol.to_rdkit() # create rdkit representation of Molecule to allow for SMARTS generation\n",
    "targ_res_num = 3\n",
    "\n",
    "atom_ids_for_SMARTS = []\n",
    "for atom in cmol.atoms: # accumulate counts and charge values across matching substructures\n",
    "    res_name, res_num     = atom.metadata['residue_name']   , atom.metadata['residue_number']\n",
    "    substruct_id, atom_id = atom.metadata['substructure_id'], atom.metadata['pdb_atom_id']\n",
    "\n",
    "    if res_num == targ_res_num: # if atom is member of representative group for any residue...\n",
    "        atom_ids_for_SMARTS.append(atom_id)             # ...collect pdb id...\n",
    "        rdmol.GetAtomWithIdx(atom_id).SetAtomMapNum(substruct_id) # ...and set atom number for labelling in SMARTS string\n",
    "\n",
    "SMARTS = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=atom_ids_for_SMARTS) # determine SMARTS for the current residue's representative group\n",
    "print(SMARTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in avgs:\n",
    "    print(res.residue_name, sum(chg for chg in res.charges.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_name = 'polyphenyleneII'\n",
    "\n",
    "polymer_folder = Path('compatible_pdbs/simple_polymers')\n",
    "output_folder = Path(f'averaged_polymers/{mol_name}')\n",
    "\n",
    "pdb_path = Path(f'compatible_pdbs/simple_polymers/{mol_name}.pdb')\n",
    "default_json = polymer_folder/f'{mol_name}.json'\n",
    "charged_json = Path(f'charged_jsons/{mol_name}_with_charges.json')\n",
    "json_path = charged_json if charged_json.exists() else default_json\n",
    "\n",
    "lc_path = output_folder/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "\n",
    "# LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "mol, topology = load_mol_and_topo(pdb_path, json_path)  # will raise exception if files for molecule are not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_path = output_folder/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "\n",
    "forcefield = ForceField(lc_path, allow_cosmetic_attributes=True)\n",
    "interchange = Interchange.from_smirnoff(force_field=forcefield, topology=topology, allow_nonintegral_charges=False) # generate Interchange with new library charges prior to writing to file\n",
    "sim = create_sim_from_interchange(interchange)\n",
    "run_simulation(sim, output_folder=Path(f'averaged_polymers/all_sims'), output_name=mol_name, num_steps=1000, record_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing to determine which atoms are not being covered by Smirnoff load from LCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PVC_matches = {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61}\n",
    "PEO_matches = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atom in mol.atoms:\n",
    "    if atom.metadata['pdb_atom_id'] not in PEO_matches:\n",
    "        print(atom.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with default_json.open('r') as mono_file:\n",
    "    jdat = json.load(mono_file)\n",
    "\n",
    "sub_ids = defaultdict(set)\n",
    "for atom in mol.atoms:\n",
    "    sub_ids[atom.metadata['residue_name']].add(atom.metadata['substructure_id'])\n",
    "\n",
    "for res_name, smirks in jdat['monomers'].items():\n",
    "    ids = {int(i) for i in re.findall('\\:(\\d+)', smirks)}\n",
    "    print(smirks, sub_ids[res_name], ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create every permutation of library charges to test which orderings produce full atomic coverage (i.e. don't need charge recalculation) \n",
    "from itertools import permutations\n",
    "\n",
    "mol_name = 'naturalrubber'\n",
    "offxml_src = Path('xml_examples/openff_unconstrained_with_library_charges-2.0.0.offxml')\n",
    "perm_output_folder = Path(f'averaged_polymers/{mol_name} perms')\n",
    "perm_output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "mol, topology, mol_files = fetch_mol(mol_name)  # will raise exception if files for molecule are not found\n",
    "cmol = generate_molecule_charges(mol, toolkit_method='openeye', partial_charge_method='am1bcc') # perform AM1BCC\n",
    "#clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "avgs = get_averaged_charges(cmol) # average charges over unique residues - placed after clear so we can see what averages are computed\n",
    "for averaged_res in avgs:\n",
    "    print(averaged_res, '\\n')\n",
    "\n",
    "for perm in permutations(avgs):\n",
    "    name = '-'.join(avg_res.residue_name for avg_res in perm)\n",
    "    perm_outpath = perm_output_folder/f'{name}.offxml'\n",
    "    forcefield, lib_chgs = write_new_library_charges(avgs, offxml_src, output_path=perm_outpath)\n",
    "\n",
    "for xml_path in perm_output_folder.iterdir():\n",
    "    print(xml_path.stem)\n",
    "    forcefield = ForceField(xml_path, allow_cosmetic_attributes=True)\n",
    "    interchange = Interchange.from_smirnoff(force_field=forcefield, topology=topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "    sim = create_sim_from_interchange(interchange)\n",
    "    run_simulation(sim, output_folder=perm_output_folder, output_name=name, num_steps=100, record_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for assigning atom ids in SMARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmol = cmol.to_rdkit()\n",
    "smarts_no_map = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=[i for i in range(5,10)])\n",
    "# how to specify atom map numbers\n",
    "i = 0\n",
    "for atom in rdmol.GetAtoms():\n",
    "    i += 1\n",
    "    atom.SetAtomMapNum(atom.GetIdx())\n",
    "smarts_yes_map = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=[i for i in range(5,10)])\n",
    "\n",
    "print(smarts_no_map)\n",
    "print(smarts_yes_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atom in rdmol.GetAtoms(): # checking that atom types match between rdkit and openff version\n",
    "    n = atom.GetIdx()\n",
    "    if atom.GetAtomicNum() != cmol.atoms[n].metadata['atomic_number']:\n",
    "        print(f'Mismatch at atom {n}')\n",
    "        break\n",
    "else:\n",
    "    print('All good!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with NX to get a feel for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(0, val=6, attr='stuff')\n",
    "G.add_node(3, val=7, attr='other')\n",
    "G.nodes[3]['attr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(1, 2, weight=10)\n",
    "G.edges[1, 2]['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing XML encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "p = Path('xml_examples/test.offxml')\n",
    "p.touch()\n",
    "\n",
    "top = ET.Element('a')\n",
    "new = ET.SubElement(top, 'b')\n",
    "new.attrib = {'first' : '4', 'second' : '5'}\n",
    " \n",
    "tree = ET.ElementTree(top)\n",
    "\n",
    "ET.dump(top) # print out tree\n",
    "tree.write(p, encoding='utf-8', xml_declaration=True) # write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:26:04) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac5336127ae73fc5f7753dcce8282dbb308069685e26d3aa94156d96b8d21be9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
