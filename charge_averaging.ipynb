{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2022.09.1 jupyter extensions\n",
      "INFO:numexpr.utils:Note: NumExpr detected 20 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import csv, json, pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from typing import Any, Callable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import networkx as nx\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdmolfiles\n",
    "\n",
    "from openff.units import unit\n",
    "from openff.interchange import Interchange\n",
    "\n",
    "from openff.toolkit.topology import Topology\n",
    "from openff.toolkit.topology.molecule import FrozenMolecule, Molecule, Atom\n",
    "from openff.toolkit.utils import toolkit_registry\n",
    "from openff.toolkit.utils.toolkits import RDKitToolkitWrapper, OpenEyeToolkitWrapper, AmberToolsToolkitWrapper\n",
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "from openff.toolkit.typing.engines.smirnoff import parameters as offtk_parameters\n",
    "\n",
    "from openmm import LangevinMiddleIntegrator\n",
    "from openmm.app import Simulation, PDBReporter, StateDataReporter\n",
    "from openmm.unit import kelvin, picosecond, picoseconds, nanometer # need to do some unit conversion with both packages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for loading and cataloging molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge calculation methods\n",
    "dotless = lambda suffix : suffix.split('.')[-1] # separate the dot from a SINGLE extension file suffix\n",
    "\n",
    "def search_mol_files(filename : str, parent_path : Path=Path.cwd()/'compatible_pdbs', extensions : tuple[str, ...]=('pdb', 'json')) -> dict[str, Path]:\n",
    "    '''Search file tree for a pdb and monomer file with matching names'''\n",
    "    mol_files = {\n",
    "        dotless(path.suffix) : path\n",
    "            for path in parent_path.glob(f'*/{filename}.*')\n",
    "                if dotless(path.suffix) in extensions\n",
    "    }\n",
    "\n",
    "    for ext in extensions:\n",
    "        if ext not in mol_files:\n",
    "            raise FileNotFoundError(f'Could not find a(n) {ext} file \\\"{filename}.{ext}\\\"')\n",
    "    else:\n",
    "        return mol_files\n",
    "\n",
    "def load_mol_and_topo(pdb_path : Path, json_path : Path, verbose : bool=False):\n",
    "    '''Load Molecule and Topology from a pdb and a monomer json file, performing residue matching on monomer units\n",
    "    Assumes that the pdb only contains has ONE simple homopolymer (will only load first molecule if multiple are present'''\n",
    "    off_topology, _, error = Topology.from_pdb_and_monomer_info(str(pdb_path), json_path, strict=True, verbose=verbose)\n",
    "    mol = next(off_topology.molecules) # get the first molecule (assumed to be the polymer of interest)\n",
    "\n",
    "    return mol, off_topology\n",
    "\n",
    "def poll_and_count_molecules(pdb_folder : Path, outname : str=None, save_fmt : str='json') -> dict[str, int]:\n",
    "    '''Takes a path to a folder containing multiple .pdb files and produces\n",
    "    a csv listing all found molecules and how many atoms each contains'''\n",
    "    mol_sizes = {}\n",
    "    mol_names = {path.stem for path in pdb_folder.iterdir()}\n",
    "    for name in mol_names:\n",
    "        try:\n",
    "            mol_files = search_mol_files(name)\n",
    "            mol, topology = load_mol_and_topo(mol_files['pdb'], mol_files['json'])  # will raise exception if files for molecule are not found\n",
    "            mol_sizes[name] = len(mol.atoms)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    if outname is not None: # also write to file if a name for the output is specified\n",
    "        outpath = pdb_folder/f'{outname}.{save_fmt}'\n",
    "        outpath.touch()\n",
    "\n",
    "        with outpath.open('w') as mol_file:\n",
    "            if save_fmt == 'csv':\n",
    "                writer = csv.writer(mol_file, delimiter=',')\n",
    "                writer.writerow(['Molecule Name', '# Atoms']) # add columns headers\n",
    "                for mol_name, mol_size in mol_sizes.items():\n",
    "                    writer.writerow([mol_name, mol_size])\n",
    "\n",
    "            elif save_fmt == 'json':\n",
    "                json.dump(mol_sizes, mol_file, indent=4)\n",
    "            else:\n",
    "                raise NotImplementedError(f'No save method for .{save_fmt} output supported')\n",
    "\n",
    "    return mol_sizes\n",
    "\n",
    "def sort_dict_by_values(targ_dict : dict, reverse : bool=False) -> dict[Any, Any]:\n",
    "    '''Sort a dictionary according to the values of each key'''\n",
    "    return { # sort dict in ascending order by size\n",
    "        key : targ_dict[key]\n",
    "            for key in sorted(targ_dict, key=lambda k : targ_dict[k], reverse=reverse)\n",
    "    }\n",
    "\n",
    "def catalog_molecules(pdb_folder : Path, monomer_folder : Path, save_fmt : str=None, outpath : Path=None) -> Optional[dict[str, int]]:\n",
    "    '''Takes paths to folders containing pdbs and corresponding monomer jsons files (assumes jsons will have same file name)\n",
    "    Will catalog names and molecules sizes of each molecule which has compatible version of both files types present\n",
    "    Can return output as dict or save to file (specified by \"saev_fmt\" kwarg)'''\n",
    "    mol_sizes = {}\n",
    "\n",
    "    pdb_dir = Path('compatible_pdbs/simple_polymers')\n",
    "    mono_dir = Path('compatible_pdbs/simple_polymers')\n",
    "\n",
    "    for path in pdb_folder.iterdir():\n",
    "        name = path.stem\n",
    "        mono_path = mono_dir/f'{path.stem}.json'\n",
    "\n",
    "        if (path.suffix == '.pdb') and mono_path.exists(): # if the current file is a pdb with a matching-named monomer json\n",
    "            mol = Molecule(str(path)) # OpenFF doesn't like PosixPaths for some reason\n",
    "            mol_sizes[name] = len(mol.atoms)\n",
    "    mol_sizes = sort_dict_by_values(mol_sizes) # sort in ascending order by molecule size\n",
    "\n",
    "    # Saving logic begins\n",
    "    if save_fmt is None:\n",
    "        return mol_sizes # return None if saving to file\n",
    "\n",
    "    if outpath is None: # TOSELF: important that this is only checked AFTER establishing the format is specified\n",
    "        raise ValueError(f'No output path specified for saving to .{save_fmt}')\n",
    "\n",
    "    if save_fmt == 'csv':\n",
    "        with outpath.open('w') as mol_file:\n",
    "            writer = csv.writer(mol_file, delimiter=',')\n",
    "            writer.writerow(['Molecule Name', '# Atoms']) # add columns headers\n",
    "            for mol_name, mol_size in mol_sizes.items():\n",
    "                writer.writerow([mol_name, mol_size])                \n",
    "    elif save_fmt == 'json':\n",
    "        with outpath.open('w') as mol_file:\n",
    "            json.dump(mol_sizes, mol_file, indent=4)\n",
    "    else:\n",
    "        raise NotImplementedError(f'No save method for .{save_fmt} output supported')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for Charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_molecule_charges(mol : Molecule, toolkit_method : str='openeye', partial_charge_method : str='am1bcc') -> Molecule:\n",
    "    '''Takes a Molecule object and computes partial charges with AM1BCC using toolkit method of choice. Returns charged molecule'''\n",
    "    toolkits = {\n",
    "        'rdkit' : RDKitToolkitWrapper,\n",
    "        'openeye' : OpenEyeToolkitWrapper,\n",
    "        'ambertools' : AmberToolsToolkitWrapper\n",
    "    }\n",
    "\n",
    "    mol.assign_partial_charges( # finally, assign partial charges using those 10 conformers generated \n",
    "        partial_charge_method=partial_charge_method, \n",
    "        toolkit_registry=toolkits.get(toolkit_method)()\n",
    "    )\n",
    "    charged_mol = mol # rename for clarity\n",
    "    # get some conformers to run elf10 charge method. By default, `mol.assign_partial_charges`\n",
    "    # uses 500 conformers, but we can generate and use 10 here for demonstration\n",
    "    # charged_mol.generate_conformers(\n",
    "    #     n_conformers=10,\n",
    "    #     rms_cutoff=0.25 * unit.angstrom,\n",
    "    #     make_carboxylic_acids_cis=True,\n",
    "    #     toolkit_registry=RDKitToolkitWrapper()\n",
    "    # ) # very slow for large polymers! \n",
    "\n",
    "    print(f'final molecular charges: {charged_mol.partial_charges}')\n",
    "    # note: the charged_mol has metadata about which monomers were assigned where as a result of the chemicaly info assignment.\n",
    "    # This can be a way to break up the molecule into repeating sections to partition the library charges \n",
    "    for atom in charged_mol.atoms:\n",
    "        assert(atom.metadata['already_matched'] == True)\n",
    "        # print(atom.metadata['residue_name'])\n",
    "    \n",
    "    return charged_mol # code for exact how thely above function works can be found in openff/toolkit/utils/openeye_wrapper.py under the assign_partial_charges()\n",
    "\n",
    "# charge averaging methods\n",
    "ChargeMap = dict[int, float] # makes typehinting clearer\n",
    "\n",
    "class ChargeDistributionStrategy(ABC):\n",
    "    '''Interface for defining how excess charge should be distributed within averaged residues\n",
    "    to ensure an overall net 0 charge for each monomer fragment'''\n",
    "    @abstractmethod\n",
    "    def determine_distribution(self, net_charge : float, base_charges : ChargeMap, struct : nx.Graph) -> ChargeMap:\n",
    "        pass\n",
    "\n",
    "class UniformDistributionStrategy(ChargeDistributionStrategy):\n",
    "    '''Simplest possible strategy, distribute any excess charge evenly among all molecules in residue\n",
    "    Each charge effectively becomes an average of averages when viewed in the context of the whole polymer'''\n",
    "    def determine_distribution(self, net_charge : float, base_charges: ChargeMap, struct: nx.Graph) -> ChargeMap:\n",
    "        charge_offset = net_charge / len(base_charges) # net charge divided evenly amongst atoms (average of averages, effectively)\n",
    "        return {sub_id : charge_offset for sub_id in base_charges}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Accumulator:\n",
    "    '''Compact container for accumulating averages'''\n",
    "    sum : float = 0.0\n",
    "    count : int = 0\n",
    "\n",
    "    @property\n",
    "    def average(self) -> float:\n",
    "        return self.sum / self.count\n",
    "\n",
    "@dataclass\n",
    "class ChargedResidue:\n",
    "    '''Dataclass for more conveniently storing averaged charges for a residue group'''\n",
    "    charges : ChargeMap\n",
    "    residue_name : str\n",
    "    SMARTS : str\n",
    "    mol_fragment : Chem.rdchem.Mol\n",
    "\n",
    "    CDS : ChargeDistributionStrategy = field(default_factory=UniformDistributionStrategy) # set default strategy here\n",
    "\n",
    "    def distrib_mono_charges(self) -> None:\n",
    "        '''Distribute any excess charge amongst residue to ensure neutral, integral net charge'''\n",
    "        net_charge = sum(chg for chg in self.charges.values())\n",
    "        distrib = self.CDS.determine_distribution(net_charge, base_charges=self.charges, struct=self.mol_fragment)\n",
    "        for sub_id, charge in self.charges.items():\n",
    "            self.charges[sub_id] = charge - distrib[sub_id] # subtract respective charge offsets from each atom's partial charge\n",
    "\n",
    "\n",
    "def find_repr_residues(cmol : Molecule) -> dict[str, int]:\n",
    "    '''Determine names and smallest residue numbers of all unique residues in charged molecule\n",
    "    Used as representatives for generating labelled SMARTS strings '''\n",
    "    rep_res_nums = defaultdict(set) # numbers of representative groups for each unique residue, used to build SMARTS strings\n",
    "    for atom in cmol.atoms: \n",
    "        rep_res_nums[atom.metadata['residue_name']].add(atom.metadata['residue_number']) # collect unique residue numbers\n",
    "\n",
    "    for res_name, ids in rep_res_nums.items():\n",
    "        rep_res_nums[res_name] = min(ids) # choose group with smallest id of each residue to denote representative group\n",
    "\n",
    "    return rep_res_nums\n",
    "\n",
    "def get_averaged_charges_orig(cmol : Molecule, monomer_data : dict[str, dict], distrib_mono_charges : bool=False) -> list[ChargedResidue]:\n",
    "    '''Takes a charged molecule and a dict of monomer structure data and averages charges for each repeating residue. \n",
    "    Returns a list of ChargedResidue objects each of which holds:\n",
    "        - A dict of the averaged charges by atom \n",
    "        - The name of the residue associated with the charges\n",
    "        - A SMARTS string of the residue's structure'''\n",
    "    rdmol = cmol.to_rdkit() # create rdkit representation of Molecule to allow for SMARTS generation\n",
    "    rep_res_nums = find_repr_residues(cmol) # determine ids of representatives of each unique residue\n",
    "\n",
    "    atom_ids_for_SMARTS = defaultdict(list)\n",
    "    res_charge_accums   = defaultdict(lambda : defaultdict(Accumulator))\n",
    "    for atom in cmol.atoms: # accumulate counts and charge values across matching substructures\n",
    "        res_name, res_num     = atom.metadata['residue_name']   , atom.metadata['residue_number']\n",
    "        substruct_id, atom_id = atom.metadata['substructure_id'], atom.metadata['pdb_atom_id']\n",
    "\n",
    "        if res_num == rep_res_nums[res_name]: # if atom is member of representative group for any residue...\n",
    "            atom_ids_for_SMARTS[res_name].append(atom_id)             # ...collect pdb id...\n",
    "            rdmol.GetAtomWithIdx(atom_id).SetAtomMapNum(substruct_id) # ...and set atom number for labelling in SMARTS string\n",
    "\n",
    "        curr_accum = res_charge_accums[res_name][substruct_id] # accumulate charge info for averaging\n",
    "        curr_accum.sum += atom.partial_charge.magnitude # eschew units (easier to handle, added back when writing to XML)\n",
    "        curr_accum.count += 1\n",
    "\n",
    "    avg_charges_by_residue = []\n",
    "    for res_name, charge_map in res_charge_accums.items():\n",
    "        # SMARTS = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=atom_ids_for_SMARTS[res_name]) # determine SMARTS for the current residue's representative group\n",
    "        SMARTS = monomer_data['monomers'][res_name] # extract SMARTS string from monomer data\n",
    "        charge_map = {substruct_id : accum.average for substruct_id, accum in charge_map.items()} \n",
    "\n",
    "        if distrib_mono_charges: # distribute any excess average charge among monomer atoms to ensure no net charge per monomer\n",
    "            chg_offset = sum(avg for avg in charge_map.values()) / len(charge_map)\n",
    "            charge_map = {sub_id : avg - chg_offset for sub_id, avg in charge_map.items()}\n",
    "        \n",
    "        avg_charges_by_residue.append(ChargedResidue(charges=charge_map, residue_name=res_name, SMARTS=SMARTS))\n",
    "\n",
    "    return avg_charges_by_residue\n",
    "\n",
    "def get_averaged_charges(cmol : Molecule, monomer_data : dict[str, dict], distrib_mono_charges : bool=True) -> list[ChargedResidue]:\n",
    "    '''Takes a charged molecule and a dict of monomer SMIRKS strings and averages charges for each repeating residue. \n",
    "    Returns a list of ChargedResidue objects, each of which holds:\n",
    "        - A dict of the averaged charges by atom \n",
    "        - The name of the residue associated with the charges\n",
    "        - A SMARTS string of the residue's structure\n",
    "        - An nx.Graph representing the structure of the residue'''\n",
    "    # rdmol = cmol.to_rdkit() # create rdkit representation of Molecule to allow for SMARTS generation\n",
    "    mol_graph = cmol.to_networkx()\n",
    "    rep_res_nums = find_repr_residues(cmol) # determine ids of representatives of each unique residue\n",
    "\n",
    "    atom_id_mapping   = defaultdict(lambda : defaultdict(int))\n",
    "    res_charge_accums = defaultdict(lambda : defaultdict(Accumulator))\n",
    "    for atom in cmol.atoms: # accumulate counts and charge values across matching substructures\n",
    "        res_name, res_num     = atom.metadata['residue_name'   ], atom.metadata['residue_number']\n",
    "        substruct_id, atom_id = atom.metadata['substructure_id'], atom.metadata['pdb_atom_id'   ]\n",
    "\n",
    "        if res_num == rep_res_nums[res_name]: # if atom is member of representative group for any residue...\n",
    "            # rdmol.GetAtomWithIdx(atom_id).SetAtomMapNum(atom_id)  # ...and set atom number for labelling in SMARTS string\n",
    "            atom_id_mapping[res_name][atom_id] = (substruct_id, atom.symbol) # ...collect pdb id...\n",
    "\n",
    "        curr_accum = res_charge_accums[res_name][substruct_id] # accumulate charge info for averaging\n",
    "        curr_accum.sum += atom.partial_charge.magnitude # eschew units (easier to handle, added back when writing to XML)\n",
    "        curr_accum.count += 1\n",
    "\n",
    "    avg_charges_by_residue = []\n",
    "    for res_name, charge_map in res_charge_accums.items():\n",
    "        # rdSMARTS = rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=atom_id_mapping[res_name].keys()) # determine SMARTS for the current residue's representative group\n",
    "        # mol_frag = rdmolfiles.MolFromSmarts(rdSMARTS) # create fragment from rdkit SMARTS to avoid wild atoms (using rdkit over nx.subgraph for more detailed atomwise info)\n",
    "        \n",
    "        SMARTS = monomer_data['monomers'][res_name] # extract SMARTS string from monomer data\n",
    "        charge_map = {substruct_id + 1: accum.average for substruct_id, accum in charge_map.items()} \n",
    "        atom_id_map = atom_id_mapping[res_name]\n",
    "\n",
    "        mol_frag = mol_graph.subgraph(atom_id_map.keys()) # isolate subgraph of residue to obtain connectivity info for charge redistribution\n",
    "        for atom_id, (substruct_id, symbol) in atom_id_map.items(): # assign additional useful info not present by default in graph\n",
    "            mol_frag.nodes[atom_id]['substruct_id'] = substruct_id\n",
    "            mol_frag.nodes[atom_id]['symbol'] = symbol\n",
    "\n",
    "        chgd_res = ChargedResidue(\n",
    "            charges=charge_map,\n",
    "            residue_name=res_name,\n",
    "            SMARTS=SMARTS,\n",
    "            mol_fragment=mol_frag\n",
    "        )\n",
    "        if distrib_mono_charges: # only distribute charges if explicitly called for (enabled by default)\n",
    "            chgd_res.distrib_mono_charges()\n",
    "        avg_charges_by_residue.append(chgd_res)\n",
    "\n",
    "    return avg_charges_by_residue, atom_id_mapping\n",
    "\n",
    "def write_new_library_charges(avgs : list[ChargedResidue], offxml_src : Path, output_path : Path) -> tuple[ForceField, list[offtk_parameters.LibraryChargeHandler]]:\n",
    "    '''Takes dict of residue-averaged charges to generate and append library charges to an .offxml file of choice, creating a new xml with the specified filename'''\n",
    "    assert(output_path.suffix == '.offxml') # ensure output path is pointing to correct file type\n",
    "    forcefield = ForceField(offxml_src)     # simpler to add library charges through forcefield API than to directly write to xml\n",
    "    lc_handler = forcefield[\"LibraryCharges\"]\n",
    "\n",
    "    lib_chgs = [] #  all library charges generated from the averaged charges for each residue\n",
    "    for averaged_res in avgs:\n",
    "        lc_entry = { # stringify charges into form usable for library charges\n",
    "            f'charge{cid}' : f'{charge} * elementary_charge' # +1 accounts for 1-index to 0-index when going from smirks atom ids to substructure ids\n",
    "                for cid, charge in averaged_res.charges.items()\n",
    "        } \n",
    "\n",
    "        lc_entry['smirks'] = averaged_res.SMARTS # add SMIRKS string to library charge entry to allow for correct labelling\n",
    "        lc_params = offtk_parameters.LibraryChargeHandler.LibraryChargeType(allow_cosmetic_attributes=True, **lc_entry) # must enable cosmetic params for general kwarg passing\n",
    "        \n",
    "        lc_handler.add_parameter(parameter=lc_params)\n",
    "        lib_chgs.append(lc_params)  # record library charges for reference\n",
    "    forcefield.to_file(output_path) # write modified library charges to new xml (avoid overwrites in case of mistakes)\n",
    "    \n",
    "    return forcefield, lib_chgs\n",
    "\n",
    "# OpenMM simulation methods\n",
    "def create_sim_from_interchange(interchange : Interchange) -> Simulation:\n",
    "    '''Sets up a Simulation object using topology and force field data as specified by an Interchange object\n",
    "    Converts topologies and positions to OpenMM format from OpenFF formats (can support GROMACS format too in future)'''\n",
    "    openmm_sys = interchange.to_openmm(combine_nonbonded_forces=True) \n",
    "    openmm_top = interchange.topology.to_openmm()\n",
    "    openmm_pos = interchange.positions.m_as(unit.nanometer) * nanometer\n",
    "    integrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.0005*picoseconds)\n",
    "\n",
    "    simulation = Simulation(openmm_top, openmm_sys, integrator)\n",
    "    simulation.context.setPositions(openmm_pos)\n",
    "\n",
    "    return simulation\n",
    "\n",
    "def run_simulation(simulation : Simulation, output_folder : Path, output_name : str='md_sim', num_steps=1000, record_freq=10) -> None:\n",
    "    '''Takes a Simulation object, performs energy minimization, and runs simulation for specified number of time steps\n",
    "    Recording PBD frames and numerical data to file at the specified frequency'''\n",
    "    folder_name = str(output_folder) # for some reason OpenMM simulations don;t like Path objects (only take strings)\n",
    "\n",
    "    # for saving pdb frames and reporting state/energy data\n",
    "    pdb_rep = PDBReporter(f'{folder_name}/{output_name}_frames.pdb', record_freq)  # save frames at the specified interval\n",
    "    state_rep = StateDataReporter(f'{folder_name}/{output_name}_data.csv', record_freq, step=True, potentialEnergy=True, temperature=True)\n",
    "    reporters = (pdb_rep, state_rep)\n",
    "\n",
    "    # minimize and run simulation\n",
    "    simulation.minimizeEnergy()\n",
    "    simulation.saveCheckpoint(f'{folder_name}/{output_name}_checkpoint.chk') # save initial minimal state to simplify reloading process\n",
    "    for rep in reporters:\n",
    "        simulation.reporters.append(rep) # add any desired reporters to simulaiton for tracking\n",
    "    simulation.step(num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running averaging code for test molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['naturalrubber', 'PEO_PLGA', 'polyvinylchloride', 'polymethylketone', 'polyethylmethacrylate', 'polyphenyleneII']\n"
     ]
    }
   ],
   "source": [
    "# Get all molecules which will be charge averaged and simulated\n",
    "pdb_folder = Path.cwd()/'compatible_pdbs'/'simple_polymers'\n",
    "counts_path = pdb_folder/'Available Polymers.json'\n",
    "\n",
    "if counts_path.exists(): # if molecules have already been polled, load names/sizes from file...\n",
    "    with counts_path.open('r') as counts_file:\n",
    "        mol_sizes = json.load(counts_file)\n",
    "else:\n",
    "    mol_sizes = poll_and_count_molecules(pdb_folder=pdb_folder, outname=counts_path.stem, save_fmt='json') # otherwise, repoll and save to file\n",
    "\n",
    "hard_polymers = ['vulcanizedrubber', 'polyphenylenesulfone'] # pathological or otherwise difficult-to-run polymers that I've encountered\n",
    "mols_to_use = [mol_name\n",
    "    for mol_name, mol_size in mol_sizes.items()\n",
    "        if mol_size < 150 # only keep polymers which are small enough for AM1BCC...\n",
    "            and mol_name not in hard_polymers # ... and not manually excluded\n",
    "]\n",
    "\n",
    "print(mols_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Current molecule: naturalrubber\n",
      "INFO:root:Found monomer JSON with precalculated charge data, using...\n",
      "INFO:root:Loading and matching molecule \"naturalrubber\"...\n",
      "INFO:root:Unpickling charged Molecule...\n",
      "INFO:root:Averaging charges over naturalrubber residues...\n",
      "WARNING:root:Library Charge file not found OR overwrite allowed, writing new Library Charge xml...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChargedResidue(charges={1: -0.03933142977101462, 2: 0.04434857038514955, 3: 0.04434857038514955, 4: -0.1171014282320227, 5: -0.16627143057329313, 6: 0.11900857357042176, 7: -0.061271426400968006, 8: 0.039208571293524334, 9: 0.039208571293524334, 11: -0.06051142620188849, 12: 0.03971857098596437, 13: 0.03971857098596437, 14: 0.03971857098596437, 10: 0.039208571293524334}, residue_name='natural_rubber_TERM1', SMARTS='[#6:1](-[#1:2])(-[#1:3])(-[#6:4](=[#6:5](-[#1:6])-[#6:7](-[#1:8])(-[#1:9])-[#1:14])-[#6:10](-[#1:11])(-[#1:12])-[#1:13])-*', mol_fragment=<networkx.classes.graph.Graph object at 0x7f5e3565e650>, CDS=<__main__.UniformDistributionStrategy object at 0x7f5e3565e7a0>) \n",
      "\n",
      "ChargedResidue(charges={4: -0.04080974277204428, 5: 0.04567358924601323, 6: 0.04567358924601323, 3: -0.1105447439238047, 2: -0.16740641026542738, 11: 0.1182702565804506, 1: -0.043683077184817724, 12: 0.046215256389517054, 13: 0.046215256389517054, 7: -0.06143474359160815, 8: 0.040610256628730364, 9: 0.040610256628730364, 10: 0.040610256628730364}, residue_name='natural_rubber', SMARTS='*-[#6:7](-[#6:5](=[#6:4](-[#6:1](-[#1:2])(-[#1:3])-*)-[#6:10](-[#1:11])(-[#1:12])-[#1:13])-[#1:6])(-[#1:8])-[#1:9]', mol_fragment=<networkx.classes.graph.Graph object at 0x7f5e3565e860>, CDS=<__main__.UniformDistributionStrategy object at 0x7f5e3565e9b0>) \n",
      "\n",
      "ChargedResidue(charges={4: -0.06105071226400988, 5: 0.03959928532796247, 6: 0.03959928532796247, 7: 0.03959928532796247, 3: -0.11097071612519878, 2: -0.17081070984048502, 12: 0.11551928227501256, 1: -0.04117071548742907, 13: 0.04596928586917264, 14: 0.04596928586917264, 8: -0.06105071226400988, 9: 0.03959928532796247, 10: 0.03959928532796247, 11: 0.03959928532796247}, residue_name='natural_rubber_TERM2', SMARTS='*-[#6:8](-[#6:6](=[#6:5](-[#6:1](-[#1:2])(-[#1:3])-[#1:4])-[#6:11](-[#1:12])(-[#1:13])-[#1:14])-[#1:7])(-[#1:9])-[#1:10]', mol_fragment=<networkx.classes.graph.Graph object at 0x7f5e3565ea70>, CDS=<__main__.UniformDistributionStrategy object at 0x7f5e3565ebc0>) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openff.toolkit.typing.engines.smirnoff.parameters:Attempting to up-convert Electrostatics section from 0.3 to 0.4\n",
      "INFO:openff.toolkit.typing.engines.smirnoff.parameters:Successfully up-converted Electrostatics section from 0.3 to 0.4. `method=\"PME\"` is now split into `periodic_potential=\"Ewald3D-ConductingBoundary\"`, `nonperiodic_potential=\"Coulomb\"`, and `exception_potential=\"Coulomb\"`.\n",
      "INFO:root:Running OpenMM sim...\n",
      "INFO:root:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform charge averaging on all target molecules which don't already have averaged LCs; \n",
    "# Load forcefield for those which already do \n",
    "sample_mols = ['naturalrubber']\n",
    "run_sims = True\n",
    "prevent_overwrites = False\n",
    "distrib_mono_charges = True\n",
    "\n",
    "offxml_src = Path('xml examples/base_library_charges.offxml')\n",
    "polymer_folder = Path('compatible_pdbs/simple_polymers')\n",
    "pickle_folder = Path('pickled_molecules/for openff-units 0.2.0')\n",
    "\n",
    "def get_cmol(mol : Molecule, pickle_path : Path) -> Molecule:\n",
    "    '''More efficient method for repeatedly obtaining a charged Molecule\n",
    "    If no molecule file is found, perform AM1BCC and save to file, otherwise load from file'''\n",
    "    if not pickle_path.exists():\n",
    "        logging.info('No extant pickled charged Molecule found, performing charging...')\n",
    "        cmol = generate_molecule_charges(mol, toolkit_method='openeye', partial_charge_method='am1bcc') # perform AM1BCC\n",
    "        with pickle_path.open('wb') as pickle_file: # write charged molecule to pickle to avoid constantly redoing AM1\n",
    "            pickle.dump(cmol, pickle_file)\n",
    "    else:\n",
    "        logging.info('Unpickling charged Molecule...')\n",
    "        with pickle_path.open('rb') as pickle_file: # read cmol from file if already extant\n",
    "            cmol = pickle.load(pickle_file)\n",
    "    return cmol\n",
    "\n",
    "for mol_name in sample_mols: #mols_to_use: #\n",
    "    # DEFINING PATHS, CREATING FOLDERS, AND FETCHING FILES\n",
    "    logging.info(f'Current molecule: {mol_name}')\n",
    "    pdb_path = Path(f'compatible_pdbs/simple_polymers/{mol_name}.pdb')#Path(f'mbuild_polymers/10-monomer chains/{mol_name}-N=10.pdb')\n",
    "    charged_json = Path(f'charged_jsons/{mol_name}_with_charges.json')\n",
    "    default_json = polymer_folder/f'{mol_name}.json'\n",
    "    if charged_json.exists():\n",
    "        logging.info('Found monomer JSON with precalculated charge data, using...')\n",
    "        json_path = charged_json\n",
    "    else:\n",
    "        logging.info('Using default monomer JSON...')\n",
    "        json_path = default_json\n",
    "\n",
    "    with json_path.open('r') as json_file:\n",
    "        mono_data = json.load(json_file)\n",
    "    \n",
    "    output_folder = Path(f'averaged_polymers/{mol_name}')\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "    lc_path = output_folder/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "    pickle_path = pickle_folder/f'{mol_name}.pkl'\n",
    "\n",
    "    # LOAD MOLECULE AND TOPOLOGY, ATTEMPT TO APPLY LIBRARY CHARGES\n",
    "    logging.info(f'Loading and matching molecule \"{mol_name}\"...')\n",
    "    mol, topology = load_mol_and_topo(pdb_path, json_path)  # will raise exception if files for molecule are not found\n",
    "    \n",
    "    if prevent_overwrites and lc_path.exists(): # check if library charges have already been generated for this molecule\n",
    "        logging.info('Obtaining partial charges from Library Charge xml...')\n",
    "        forcefield = ForceField(lc_path, allow_cosmetic_attributes=True)\n",
    "    else:\n",
    "        cmol = get_cmol(mol, pickle_path=pickle_path)\n",
    "        #clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "        logging.info(f'Averaging charges over {mol_name} residues...')\n",
    "        avgs, atom_id_mapping = get_averaged_charges(cmol, monomer_data=mono_data, distrib_mono_charges=distrib_mono_charges) # average charges over unique residues - placed after clear so we can see what averages are computed\n",
    "        for averaged_res in avgs:\n",
    "            print(averaged_res, '\\n')\n",
    "\n",
    "        logging.warning('Library Charge file not found OR overwrite allowed, writing new Library Charge xml...')\n",
    "        forcefield, lib_chgs = write_new_library_charges(avgs, offxml_src, output_path=lc_path)\n",
    "        \n",
    "        # CREATE JSON WITH AVERAGED CHARGES IF ONE DOES NOT ALREADY EXIST\n",
    "        if not charged_json.exists():\n",
    "            logging.info('Writing new monomer JSON with charge data...')\n",
    "            with default_json.open('r') as old_json:\n",
    "                json_dat = json.load(old_json)\n",
    "\n",
    "            charge_entry = {avgd_res.residue_name : avgd_res.charges for avgd_res in avgs}\n",
    "            json_dat['charges'] = charge_entry\n",
    "\n",
    "            charged_json.touch()\n",
    "            with charged_json.open('w') as new_json:\n",
    "                json.dump(json_dat, new_json, indent=4)\n",
    "\n",
    "    # RUN OpenMM SIMULATION FOR TARGET MOLECULE\n",
    "    if run_sims:\n",
    "        logging.info('Running OpenMM sim...')\n",
    "        forcefield = ForceField(lc_path, allow_cosmetic_attributes=True)\n",
    "        interchange = Interchange.from_smirnoff(force_field=forcefield, topology=topology, charge_from_molecules=[cmol]) # generate Interchange with new library charges prior to writing to file\n",
    "        sim = create_sim_from_interchange(interchange)\n",
    "        run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=10000, record_freq=10)\n",
    "    logging.info(f'Successfully completed actions on {mol_name}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sim\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim' is not defined"
     ]
    }
   ],
   "source": [
    "sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac5336127ae73fc5f7753dcce8282dbb308069685e26d3aa94156d96b8d21be9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
