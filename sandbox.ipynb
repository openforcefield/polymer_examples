{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Optional, Union\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from rdkit import Chem\n",
    "from openff.units import unit\n",
    "from openff.interchange import Interchange\n",
    "\n",
    "from openff.toolkit.topology import Topology\n",
    "from openff.toolkit.topology.molecule import FrozenMolecule, Molecule, Atom\n",
    "from openff.toolkit.utils import toolkit_registry\n",
    "from openff.toolkit.utils.toolkits import RDKitToolkitWrapper, OpenEyeToolkitWrapper, AmberToolsToolkitWrapper\n",
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "from openff.toolkit.typing.engines.smirnoff import parameters as offtk_parameters\n",
    "\n",
    "from openmm import LangevinMiddleIntegrator\n",
    "from openmm.app import Simulation, PDBReporter, StateDataReporter\n",
    "from openmm.unit import kelvin, picosecond, picoseconds, nanometer # need to do some unit conversion with both packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions for charge averaging and simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge calculation methods\n",
    "def fetch_mol(filename : str, parent_path : Path=Path.cwd()/'compatible_pdbs', extensions : tuple[str, ...]=('pdb', 'json'), verbose : bool=False) -> tuple[Molecule, Topology]:\n",
    "    '''Takes the name of a molecule and searches for associated .pbd and .json files\n",
    "    If found, will load Topology and extract first found molecule (assume that the topology only has ONE simple homopolymer)\n",
    "    Returns the found Topology and Molecule'''\n",
    "    mol_files = {\n",
    "        ext : path\n",
    "            for path in parent_path.glob('**/*.*')\n",
    "                for ext in extensions\n",
    "                    if path.name == f'{filename}.{ext}'\n",
    "    }\n",
    "\n",
    "    for ext in extensions:\n",
    "        if ext not in mol_files:\n",
    "            raise FileNotFoundError(f'Could not find a(n) {ext} file \\\"{filename}.{ext}\\\"')\n",
    "    else:\n",
    "        off_topology, _, error = Topology.from_pdb_and_monomer_info(str(mol_files['pdb']), mol_files['json'], strict=True, verbose=verbose)\n",
    "        mol = next(off_topology.molecules) # get the first molecule (assumed to be the polymer of interest)\n",
    "\n",
    "        return mol, off_topology\n",
    "\n",
    "def poll_and_count_molecules(pdb_folder : Path, outname : str=None) -> dict[str, int]:\n",
    "    '''Takes a path to a folder containing multiple .pdb files and produces\n",
    "    a csv listing all found molecules and how many atoms each contains'''\n",
    "    mol_sizes = {}\n",
    "    mol_names = {path.stem for path in pdb_folder.iterdir()}\n",
    "    for name in mol_names:\n",
    "        try:\n",
    "            mol, topology = fetch_mol(name)  # will raise exception if files for molecule are not found\n",
    "            mol_sizes[name] = len(mol.atoms)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    if outname is not None: # also write to file if a name for the output is specified\n",
    "        outpath = pdb_folder/f'{outname}.csv'\n",
    "        outpath.touch()\n",
    "\n",
    "        with outpath.open('w') as mol_file:\n",
    "            writer = csv.writer(mol_file, delimiter=',')\n",
    "            writer.writerow(['Molecule Name', '# Atoms']) # add columns headers\n",
    "            for mol_name, mol_size in mol_sizes.items():\n",
    "                writer.writerow([mol_name, mol_size])\n",
    "\n",
    "    return mol_sizes\n",
    "\n",
    "def generate_molecule_charges(mol : Molecule, toolkit_method : str='openeye', partial_charge_method : str='am1bcc') -> Molecule:\n",
    "    '''Takes a Molecule object and computes partial charges with AM1BCC using toolkit method of choice. Returns charged molecule'''\n",
    "    toolkits = {\n",
    "        'rdkit' : RDKitToolkitWrapper,\n",
    "        'openeye' : OpenEyeToolkitWrapper,\n",
    "        'ambertools' : AmberToolsToolkitWrapper\n",
    "    }\n",
    "\n",
    "    mol.assign_partial_charges( # finally, assign partial charges using those 10 conformers generated \n",
    "        partial_charge_method=partial_charge_method, \n",
    "        toolkit_registry=toolkits.get(toolkit_method)()\n",
    "    )\n",
    "    charged_mol = mol # rename for clarity\n",
    "    # get some conformers to run elf10 charge method. By default, `mol.assign_partial_charges`\n",
    "    # uses 500 conformers, but we can generate and use 10 here for demonstration\n",
    "    # charged_mol.generate_conformers(\n",
    "    #     n_conformers=10,\n",
    "    #     rms_cutoff=0.25 * unit.angstrom,\n",
    "    #     make_carboxylic_acids_cis=True,\n",
    "    #     toolkit_registry=RDKitToolkitWrapper()\n",
    "    # ) # very slow for large polymers! \n",
    "\n",
    "    print(f'final molecular charges: {charged_mol.partial_charges}')\n",
    "    # note: the charged_mol has metadata about which monomers were assigned where as a result of the chemicaly info assignment.\n",
    "    # This can be a way to break up the molecule into repeating sections to partition the library charges \n",
    "    for atom in charged_mol.atoms:\n",
    "        assert(atom.metadata['already_matched'] == True)\n",
    "        # print(atom.metadata['residue_name'])\n",
    "    \n",
    "    return charged_mol # code for exact how thely above function works can be found in openff/toolkit/utils/openeye_wrapper.py under the assign_partial_charges()\n",
    "\n",
    "# charge averaging methods\n",
    "AveragedChargeMap = defaultdict[str, dict[int, float]] # makes typehinting clearer\n",
    "\n",
    "@dataclass\n",
    "class Accumulator:\n",
    "    '''Compact container for accumulating averages'''\n",
    "    sum : float = 0.0\n",
    "    count : int = 0\n",
    "\n",
    "    @property\n",
    "    def average(self) -> float:\n",
    "        return self.sum / self.count\n",
    "\n",
    "@dataclass\n",
    "class AvgResidueCharges:\n",
    "    '''Dataclass for more conveniently storing averaged charges for a residue group'''\n",
    "    charges : dict[int, float]\n",
    "    residue_name : str\n",
    "    SMARTS : str\n",
    "\n",
    "def find_repr_residues(cmol : Molecule) -> dict[str, int]:\n",
    "    '''Determine names and smallest residue numbers of all unique residues in charged molecule\n",
    "    Used as representatives for generating labelled SMARTS strings '''\n",
    "    rep_res_nums = defaultdict(set) # numbers of representative groups for each unique residue, used to build SMARTS strings\n",
    "    for atom in cmol.atoms: \n",
    "        rep_res_nums[atom.metadata['residue_name']].add(atom.metadata['residue_number']) # collect unique residue numbers\n",
    "\n",
    "    for res_name, ids in rep_res_nums.items():\n",
    "        rep_res_nums[res_name] = min(ids) # choose group with smallest id of each residue to denote representative group\n",
    "\n",
    "    return rep_res_nums\n",
    "\n",
    "def get_averaged_charges(cmol : Molecule, index_by : str='SMARTS') -> list[AvgResidueCharges]:\n",
    "    '''Takes a charged molecule and averages charges for each repeating residue. \n",
    "    Returns a list of AvgResidueCharge objects each of which holds:\n",
    "        - A dict of the averaged charges by atom \n",
    "        - The name of the residue associated with the charges\n",
    "        - A SMARTS string of the residue's structure'''\n",
    "    rdmol = cmol.to_rdkit() # create rdkit representation of Molecule to allow for SMARTS generation\n",
    "    rep_res_nums = find_repr_residues(cmol) # determine ids of representatives of each unique residue\n",
    "\n",
    "    atom_ids_for_SMARTS = defaultdict(list)\n",
    "    res_charge_accums   = defaultdict(lambda : defaultdict(Accumulator))\n",
    "    for atom in cmol.atoms: # accumulate counts and charge values across matching substructures\n",
    "        res_name, substruct_id, atom_id = atom.metadata['residue_name'], atom.metadata['substructure_id'], atom.metadata['pdb_atom_id']\n",
    "        if atom.metadata['residue_number'] == rep_res_nums[res_name]: # if atom is member of representative group for any residue...\n",
    "            atom_ids_for_SMARTS[res_name].append(atom_id)             # ...collect pdb id...\n",
    "            rdmol.GetAtomWithIdx(atom_id).SetAtomMapNum(substruct_id) # ...and set atom number for labelling in SMARTS string\n",
    "\n",
    "        curr_accum = res_charge_accums[res_name][substruct_id] # accumulate charge info for averaging\n",
    "        curr_accum.sum += atom.partial_charge.magnitude # eschew units (easier to handle, added back when writing to XML)\n",
    "        curr_accum.count += 1\n",
    "\n",
    "    avg_charges_by_residue = []\n",
    "    for res_name, charge_map in res_charge_accums.items():\n",
    "        SMARTS = Chem.rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=atom_ids_for_SMARTS[res_name]) # determine SMARTS for the current residue's representative group\n",
    "        charge_map = {substruct_id : accum.average for substruct_id, accum in charge_map.items()}\n",
    "        charge_container = AvgResidueCharges(charges=charge_map, residue_name=res_name, SMARTS=SMARTS)\n",
    "        avg_charges_by_residue.append(charge_container)\n",
    "\n",
    "    return avg_charges_by_residue\n",
    "\n",
    "def write_new_library_charges(avgs : list[AvgResidueCharges], offxml_src : Path, output_path : Path) -> tuple[ForceField, list[offtk_parameters.LibraryChargeHandler]]:\n",
    "    '''Takes dict of residue-averaged charges to generate and append library charges to an .offxml file of choice, creating a new xml with the specified filename'''\n",
    "    assert(output_path.suffix == '.offxml') # ensure output path is pointing to correct file type\n",
    "    forcefield = ForceField(offxml_src)     # simpler to add library charges through forcefield API than to directly write to xml\n",
    "    lc_handler = forcefield[\"LibraryCharges\"]\n",
    "\n",
    "    lib_chgs = [] #  all library charges generated from the averaged charges for each residue\n",
    "    for averaged_res in avgs:\n",
    "        lc_entry = {f'charge{cid}' : f'{charge} * elementary_charge' for cid, charge in averaged_res.charges.items()} # stringify charges into form usable for library charges\n",
    "        lc_entry['smirks'] = averaged_res.SMARTS # add SMIRKS string to library charge entry to allow for correct labelling\n",
    "        lc_params = offtk_parameters.LibraryChargeHandler.LibraryChargeType(allow_cosmetic_attributes=True, **lc_entry) # must enable cosmetic params for general kwarg passing\n",
    "        \n",
    "        lc_handler.add_parameter(parameter=lc_params)\n",
    "        lib_chgs.append(lc_params)   # record library charges for reference\n",
    "    forcefield.to_file(output_path) # write modified library charges to new xml (avoid overwrites in case of mistakes)\n",
    "    \n",
    "    return forcefield, lib_chgs\n",
    "\n",
    "# OpenMM simulation methods\n",
    "def create_sim_from_interchange(interchange : Interchange) -> Simulation:\n",
    "    '''Sets up a Simulation object using topology and force field data as specified by an Interchange object\n",
    "    Converts topologies and positions to OpenMM format from OpenFF formats (can support GROMACS format too in future)'''\n",
    "    openmm_sys = interchange.to_openmm(combine_nonbonded_forces=True) \n",
    "    openmm_top = interchange.topology.to_openmm()\n",
    "    openmm_pos = interchange.positions.m_as(unit.nanometer) * nanometer\n",
    "    integrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.0005*picoseconds)\n",
    "\n",
    "    simulation = Simulation(openmm_top, openmm_sys, integrator)\n",
    "    simulation.context.setPositions(openmm_pos)\n",
    "\n",
    "    return simulation\n",
    "\n",
    "def run_simulation(simulation : Simulation, output_folder : Path, output_name : str='md_sim', num_steps=1000, record_freq=10) -> None:\n",
    "    '''Takes a Simulation object, performs energy minimization, and runs simulation for specified number of time steps\n",
    "    Recording PBD frames and numerical data to file at the specified frequency'''\n",
    "    folder_name = str(output_folder) # for some reason OpenMM simulations don;t like Path objects (only take strings)\n",
    "\n",
    "    # for saving pdb frames and reporting state/energy data\n",
    "    pdb_rep = PDBReporter(f'{folder_name}/{output_name}_frames.pdb', record_freq)  # save frames at the specified interval\n",
    "    state_rep = StateDataReporter(f'{folder_name}/{output_name}_data.csv', record_freq, step=True, potentialEnergy=True, temperature=True)\n",
    "    reporters = (pdb_rep, state_rep)\n",
    "\n",
    "    # minimize and run simulation\n",
    "    simulation.minimizeEnergy()\n",
    "    simulation.saveCheckpoint(f'{folder_name}/{output_name}_checkpoint.chk') # save initial minimal state to simplify reloading process\n",
    "    for rep in reporters:\n",
    "        simulation.reporters.append(rep) # add any desired reporters to simulaiton for tracking\n",
    "    simulation.step(num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running averaging code for test molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgResidueCharges(charges={0: -0.5940300232808416, 1: 0.13015000456168005, 2: 0.12320999735190223, 7: 0.40027999811961007, 5: 0.03387999841167281, 6: 0.03387999841167281, 3: 0.03731999852849791, 4: 0.03731999852849791}, residue_name='peg_TERM1', SMARTS='[#8](-[#6:1](-[#6:2](-[H:3])-[H:4])(-[H:5])-[H:6])-[H:7]') \n",
      "\n",
      "AvgResidueCharges(charges={2: -0.4070160037915532, 1: 0.12583200120522328, 0: 0.1325919979174311, 3: 0.044027999873893955, 4: 0.044027999873893955, 5: 0.051851999099987243, 6: 0.051851999099987243}, residue_name='peg', SMARTS='[#8:2]-[#6:1](-[#6](-[H:5])-[H:6])(-[H:3])-[H:4]') \n",
      "\n",
      "AvgResidueCharges(charges={0: -0.4371033317487066, 1: 0.6301166805981969, 2: -0.514863332772317, 3: 0.11162666662130505, 4: -0.11567333406613518, 8: 0.1092099987824137, 5: 0.06476333423051983, 6: 0.06476333423051983, 7: 0.06476333423051983}, residue_name='plga1', SMARTS='[#8]-[#6:1](=[#8:2])-[#6:3](-[#6:4](-[H:5])(-[H:6])-[H:7])-[H:8]') \n",
      "\n",
      "AvgResidueCharges(charges={0: -0.4363533364376053, 1: 0.6391933355092382, 2: -0.5020599967877691, 3: 0.09038333280477673, 4: 0.0789933322230354, 5: 0.0789933322230354}, residue_name='plga2', SMARTS='[#8]-[#6:1](=[#8:2])-[#6:3](-[H:4])-[H:5]') \n",
      "\n",
      "AvgResidueCharges(charges={0: -0.41534999078915763, 1: 0.1302700036127741, 2: -0.09703999823735406, 6: 0.022719999115603667, 7: 0.022719999115603667, 3: 0.046190000410812594, 4: 0.046190000410812594, 5: 0.046190000410812594}, residue_name='peg_TERM2', SMARTS='[#8]-[#6:1](-[#6:2](-[H:3])(-[H:4])-[H:5])(-[H:6])-[H:7]') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mol_sizes = poll_and_count_molecules(pdb_folder=Path.cwd()/'compatible_pdbs'/'simple_polymers')#, outname='Available Polymers')  \n",
    "hard_polymers = ['vulcanizedrubber', 'polyphenylenesulfone'] # pathological or otherwise difficult-to-run polymers that I've encountered\n",
    "for problem_child in hard_polymers: # remove all difficult cases from batch\n",
    "    mol_sizes.pop(problem_child) # names are fun :)\n",
    "\n",
    "print(mol_sizes)\n",
    "for mol_name, mol_size in mol_sizes.items():\n",
    "    if mol_size < 150:\n",
    "        print(mol_name)\n",
    "        offxml_src = Path('xml examples/openff_unconstrained_with_library_charges-2.0.0.offxml')\n",
    "        output_folder = Path(f'averaged_polymers/{mol_name}')\n",
    "        output_folder.mkdir(exist_ok=True)\n",
    "        lc_path = output_folder/f'new {mol_name} charges.offxml' # path to output library charges to\n",
    "\n",
    "        mol, topology = fetch_mol(mol_name)  # will raise exception if files for molecule are not found\n",
    "        if lc_path.exists(): # check if library charges have already been generated for this molecule\n",
    "            forcefield = ForceField(lc_path, allow_cosmetic_attributes=True)\n",
    "        else:\n",
    "            cmol = generate_molecule_charges(mol, toolkit_method='openeye', partial_charge_method='am1bcc') # perform AM1BCC\n",
    "            clear_output() # for Jupyter notebooks only, can freely comment this out\n",
    "            avgs = get_averaged_charges(cmol) # average charges over unique residues - placed after clear so we can see what averages are computed\n",
    "            for averaged_res in avgs:\n",
    "                print(averaged_res, '\\n')\n",
    "\n",
    "            forcefield, lib_chgs = write_new_library_charges(avgs, offxml_src, output_path=lc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOSELF: confirm whether creating Interchange is really re-doing AM1BCC\n",
    "interchange = Interchange.from_smirnoff(force_field=forcefield, topology=topology) # generate Interchange with new library charges prior to writing to file\n",
    "sim = create_sim_from_interchange(interchange)\n",
    "run_simulation(sim, output_folder=output_folder, output_name=mol_name, num_steps=10000, record_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmol.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "[i for i in permutations(range(3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for assigning atom ids in SMARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmol = cmol.to_rdkit()\n",
    "smarts_no_map = Chem.rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=[i for i in range(5,10)])\n",
    "# how to specify atom map numbers\n",
    "i = 0\n",
    "for atom in rdmol.GetAtoms():\n",
    "    i += 1\n",
    "    atom.SetAtomMapNum(atom.GetIdx())\n",
    "smarts_yes_map = Chem.rdmolfiles.MolFragmentToSmarts(rdmol, atomsToUse=[i for i in range(5,10)])\n",
    "\n",
    "print(smarts_no_map)\n",
    "print(smarts_yes_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atom in rdmol.GetAtoms(): # checking that atom types match between rdkit and openff version\n",
    "    n = atom.GetIdx()\n",
    "    if atom.GetAtomicNum() != cmol.atoms[n].metadata['atomic_number']:\n",
    "        print(f'Mismatch at atom {n}')\n",
    "        break\n",
    "else:\n",
    "    print('All good!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with NX to get a feel for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(0, val=6, attr='stuff')\n",
    "G.add_node(3, val=7, attr='other')\n",
    "G.nodes[3]['attr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(1, 2, weight=10)\n",
    "G.edges[1, 2]['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing XML encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "p = Path('xml examples/test.offxml')\n",
    "p.touch()\n",
    "\n",
    "top = ET.Element('a')\n",
    "new = ET.SubElement(top, 'b')\n",
    "new.attrib = {'first' : '4', 'second' : '5'}\n",
    " \n",
    "tree = ET.ElementTree(top)\n",
    "\n",
    "ET.dump(top) # print out tree\n",
    "tree.write(p, encoding='utf-8', xml_declaration=True) # write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('openff-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f9cdd2e387d00c633121ae0d6167f9bd222ae4f015041a103877077aa42441e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
